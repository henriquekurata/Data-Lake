**********CONSTRUINDO DATA LAKE ON-PREMISSES COM DOCKER**********

- Ferramentas: Docker, Hadoop, JDK

- Passos:
1- Download Hadoop e JDK;
2- Exceutar o arquivo de imagem dockerfile;
3- Criar container;
4- Fazer ajustes no conainer.

- Comandos:
# Preparação do NameNode
1- Faça o download do Apache Hadoop e do JDK 8, coloque na pasta "binarios", descompacte os arquivos e renomeie as pastas para "hadoop" e "jdk".
Download direto na documentação do hadoop e java.

2- Abra o terminal ou prompt de comando, navegue até a pasta do NameNode e execute a instrução abaixo para criar a imagem:

docker build . -t namenode:dsa

DOCKERFILE:
# Arquivo de Configuração do NameNode no Cluster HDFS
# Data Science Academy

# O sistema operacional será o Ubuntu na versão mais atual
# https://hub.docker.com/_/ubuntu
FROM ubuntu:latest

# Updates e instalações
RUN \
  apt-get update && apt-get install -y \
  openssh-server \
  python3 \
  rsync \
  sudo \
  arp-scan \
  net-tools \
  iputils-ping \
  vim \
  && apt-get clean

# Cria usuário para a instalação do Hadoop
RUN useradd -m hduser && echo "hduser:supergroup" | chpasswd && adduser hduser sudo && echo "hduser ALL=(ALL) NOPASSWD:ALL" >> /etc/sudoers && cd /usr/bin/ && sudo ln -s python3 python

# Copia o arquivo de configuração do ssh
ADD ./config-files/ssh_config /etc/ssh/ssh_config

# Muda o usuário
USER hduser

# Pasta de trabalho
WORKDIR /home/hduser

# Cria a chave ssh
RUN ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa && cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys && chmod 0600 ~/.ssh/authorized_keys

# Usuário de trabalho
ENV HDFS_NAMENODE_USER=hduser
ENV HDFS_DATANODE_USER=hduser
ENV HDFS_SECONDARYNAMENODE_USER=hduser
ENV YARN_RESOURCEMANAGER_USER=hduser
ENV YARN_NODEMANAGER_USER=hduser

# Copia os binários do JDK
ADD ./binarios/jdk ./jdk

# Variáveis de ambiente JDK
ENV JAVA_HOME=/home/hduser/jdk
ENV PATH=$PATH:$JAVA_HOME:$JAVA_HOME/bin

# Copia os binários do Hadoop
ADD ./binarios/hadoop ./hadoop

# Variáveis de ambiente do Hadoop
ENV HADOOP_HOME=/home/hduser/hadoop
ENV PATH=$PATH:$HADOOP_HOME
ENV PATH=$PATH:$HADOOP_HOME/bin
ENV PATH=$PATH:$HADOOP_HOME/sbin

# Pastas para os arquivos do NameNode
RUN mkdir /home/hduser/hdfs
RUN mkdir /home/hduser/hdfs/namenode

# Variáveis de ambiente
RUN echo "PATH=$PATH:$JAVA_HOME/bin" >> ~/.bashrc
RUN echo "PATH=$PATH:$HADOOP_HOME/bin" >> ~/.bashrc
RUN echo "PATH=$PATH:$HADOOP_HOME/sbin" >> ~/.bashrc

# Copia os arquivos de configuração
ADD ./config-files/hadoop-env.sh $HADOOP_HOME/etc/hadoop/
ADD ./config-files/core-site.xml $HADOOP_HOME/etc/hadoop/
ADD ./config-files/hdfs-site.xml $HADOOP_HOME/etc/hadoop/
ADD ./config-files/workers $HADOOP_HOME/etc/hadoop/

# Portas que poderão ser usadas
EXPOSE 50070 50075 50010 50020 50090 8020 9000 9864 9870 8030 8031 8032 8033 8040 8042 22


# Documentação do docker build:
https://docs.docker.com/engine/reference/commandline/build/

3- Precisaremos de uma rede. Verifique as redes disponíveis e então crie uma com as instruções abaixo:
docker network ls
docker network create -d bridge dsa_dl_net

4- Crie e inicialize o container com a instrução abaixo:
docker run -it -d --net dsa_dl_net --hostname hdpmaster -p 9870:9870 -p 50030:50030 -p 8020:8020 --name namenode namenode:dsa 

# Documentação do doccker run:
https://docs.docker.com/engine/reference/commandline/run/

5- Acesse o container usando a CLI no Docker Desktop e execute as instruções abaixo:
# Restart do serviço ssh
sudo service ssh restart

# Ajuste dos privilégios
sudo chown -R hduser:hduser /home/hduser/jdk
sudo chown -R hduser:hduser /home/hduser/hadoop

# Formate o NameNode (somente na primeira execução)
hdfs namenode -format

# Start do serviço do NameNode
hdfs --daemon start namenode

# Se precisar parar o serviço:
hdfs --daemon stop namenode

# Acesse: http://localhost:9870/

Obs: Para mais informações sobre os arquivos de configurações do hadoop, basta acessar o site http://apache.github.io/hadoop/ na aba configuration


# Preparação dos DataNodes

1- Faça o download do Apache Hadoop e do JDK 8, coloque na pasta "binarios", descompacte os arquivos e renomeie as pastas. O procedimento é o mesmo usado no capítulo anterior.

2- Abra o terminal ou prompt de comando, navegue até a pasta do DataNode e execute a instrução abaixo para criar a imagem:
docker build . -t datanode:dsa

# Arquivo de Configuração do DataNode no Cluster HDFS

# O sistema operacional será o Ubuntu na versão mais atual
# https://hub.docker.com/_/ubuntu
FROM ubuntu:latest

# Updates e instalações
RUN \
  apt-get update && apt-get install -y \
  openssh-server \
  python3 \
  rsync \
  sudo \
  arp-scan \
  net-tools \
  iputils-ping \
  vim \
  && apt-get clean

# Cria usuário para a instalação do Hadoop
RUN useradd -m hduser && echo "hduser:supergroup" | chpasswd && adduser hduser sudo && echo "hduser ALL=(ALL) NOPASSWD:ALL" >> /etc/sudoers && cd /usr/bin/ && sudo ln -s python3 python

# Copia o arquivo de configuração do ssh
ADD ./config-files/ssh_config /etc/ssh/ssh_config

# Muda o usuário
USER hduser

# Pasta de trabalho
WORKDIR /home/hduser

# Usuário de trabalho
ENV HDFS_NAMENODE_USER=hduser
ENV HDFS_DATANODE_USER=hduser
ENV HDFS_SECONDARYNAMENODE_USER=hduser
ENV YARN_RESOURCEMANAGER_USER=hduser
ENV YARN_NODEMANAGER_USER=hduser

# Copia os binários do JDK
ADD ./binarios/jdk ./jdk

# Variáveis de ambiente JDK
ENV JAVA_HOME=/home/hduser/jdk
ENV PATH=$PATH:$JAVA_HOME:$JAVA_HOME/bin

# Copia os binários do Hadoop
ADD ./binarios/hadoop ./hadoop

# Variáveis de ambiente do Hadoop
ENV HADOOP_HOME=/home/hduser/hadoop
ENV PATH=$PATH:$HADOOP_HOME
ENV PATH=$PATH:$HADOOP_HOME/bin
ENV PATH=$PATH:$HADOOP_HOME/sbin

# Pastas para os arquivos do DataNode
RUN mkdir /home/hduser/hdfs
RUN mkdir /home/hduser/hdfs/datanode

# Copia os arquivos de configuração
ADD ./config-files/hadoop-env.sh $HADOOP_HOME/etc/hadoop/
ADD ./config-files/core-site.xml $HADOOP_HOME/etc/hadoop/
ADD ./config-files/hdfs-site.xml $HADOOP_HOME/etc/hadoop/
ADD ./config-files/workers $HADOOP_HOME/etc/hadoop/

# Portas que poderão ser usadas
EXPOSE 22


# Documentação do docker build:
https://docs.docker.com/engine/reference/commandline/build/

3- Precisaremos de uma rede. Verifique se a rede dsa_dl_net criada no capítulo anterior está criada:
docker network ls

4- Crie e inicialize o container de cada datanode (criaremos 2) com cada instrução abaixo:
docker run -it -d --net dsa_dl_net --hostname datanode1 --name datanode1 datanode:dsa

docker run -it -d --net dsa_dl_net --hostname datanode2 --name datanode2 datanode:dsa

# Documentação do doccker run:
https://docs.docker.com/engine/reference/commandline/run/

5- Acesse CADA container usando a CLI no Docker Desktop e execute as instruções abaixo:
# Restart do serviço ssh
sudo service ssh restart

# Ajuste dos privilégios
sudo chown -R hduser:hduser /home/hduser/jdk
sudo chown -R hduser:hduser /home/hduser/hadoop

# Crie a pasta ~/.ssh
mkdir ~/.ssh

# Crie o arquivo ~/.ssh/authorized_keys
touch ~/.ssh/authorized_keys

# Ajuste o privilégio
chmod 600 ~/.ssh/authorized_keys

# Copie a chave que está em /home/hduser/.ssh/authorized_keys no NameNode para o mesmo arquivo em cada datanode.

# Start do serviço do DataNode
hdfs --daemon start datanode

# Se precisar parar o serviço:
hdfs --daemon stop datanode

# Acesse o painel de gestão pelo navegador
Obs: Se não funcionar o endereço 0.0.0.0 use localhost

Obs: Para inicializar o datanode é necessário limpar a pasta /home/hduser/hdfs/datanode/ (sudo rm -rf *)






**********DATA LAKE ON-PREMISSES - CAMADA DE MENSAGENS - PARTE 1**********

- Ferramentas: Kafta (Confluent)

- Passos:
1- Executar docker-compose extraído do git;
2-

- Comandos:
docker-compose para criação de imagens e container docker do Kafka:
---
version: '2'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.2
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  broker:
    image: confluentinc/cp-server:7.3.2
    hostname: broker
    container_name: broker
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker:29092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'true'
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'

  schema-registry:
    image: confluentinc/cp-schema-registry:7.3.2
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - broker
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:29092'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081

  connect:
    image: cnfldemos/cp-server-connect-datagen:0.5.3-7.1.0
    hostname: connect
    container_name: connect
    depends_on:
      - broker
      - schema-registry
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'broker:29092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      # CLASSPATH required due to CC-2422
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-7.3.2.jar
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR

  control-center:
    image: confluentinc/cp-enterprise-control-center:7.3.2
    hostname: control-center
    container_name: control-center
    depends_on:
      - broker
      - schema-registry
      - connect
      - ksqldb-server
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:29092'
      CONTROL_CENTER_CONNECT_CONNECT-DEFAULT_CLUSTER: 'connect:8083'
      CONTROL_CENTER_KSQL_KSQLDB1_URL: "http://ksqldb-server:8088"
      CONTROL_CENTER_KSQL_KSQLDB1_ADVERTISED_URL: "http://localhost:8088"
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      PORT: 9021

  ksqldb-server:
    image: confluentinc/cp-ksqldb-server:7.3.2
    hostname: ksqldb-server
    container_name: ksqldb-server
    depends_on:
      - broker
      - connect
    ports:
      - "8088:8088"
    environment:
      KSQL_CONFIG_DIR: "/etc/ksql"
      KSQL_BOOTSTRAP_SERVERS: "broker:29092"
      KSQL_HOST_NAME: ksqldb-server
      KSQL_LISTENERS: "http://0.0.0.0:8088"
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      KSQL_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      KSQL_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      KSQL_KSQL_CONNECT_URL: "http://connect:8083"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_REPLICATION_FACTOR: 1
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: 'true'
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: 'true'

  ksqldb-cli:
    image: confluentinc/cp-ksqldb-cli:7.3.2
    container_name: ksqldb-cli
    depends_on:
      - broker
      - connect
      - ksqldb-server
    entrypoint: /bin/sh
    tty: true

  ksql-datagen:
    image: confluentinc/ksqldb-examples:7.3.2
    hostname: ksql-datagen
    container_name: ksql-datagen
    depends_on:
      - ksqldb-server
      - broker
      - schema-registry
      - connect
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                       cub kafka-ready -b broker:29092 1 40 && \
                       echo Waiting for Confluent Schema Registry to be ready... && \
                       cub sr-ready schema-registry 8081 40 && \
                       echo Waiting a few seconds for topic creation to finish... && \
                       sleep 11 && \
                       tail -f /dev/null'"
    environment:
      KSQL_CONFIG_DIR: "/etc/ksql"
      STREAMS_BOOTSTRAP_SERVERS: broker:29092
      STREAMS_SCHEMA_REGISTRY_HOST: schema-registry
      STREAMS_SCHEMA_REGISTRY_PORT: 8081

  rest-proxy:
    image: confluentinc/cp-kafka-rest:7.3.2
    depends_on:
      - broker
      - schema-registry
    ports:
      - 8082:8082
    hostname: rest-proxy
    container_name: rest-proxy
    environment:
      KAFKA_REST_HOST_NAME: rest-proxy
      KAFKA_REST_BOOTSTRAP_SERVERS: 'broker:29092'
      KAFKA_REST_LISTENERS: "http://0.0.0.0:8082"
      KAFKA_REST_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'


#Dentro do Kafka: localhost:9021
Criar os topics e os connects (name /* kafka.topic / quickstart (igual ao name))


#Agora é acessar o menu KsqlDB para execução de query SQL:
# Cria um stream (objeto imutável) para um dos tópicos
CREATE STREAM pageviews_stream WITH (KAFKA_TOPIC='pageviews', VALUE_FORMAT='AVRO');

# Select nos dados de stream
SELECT * FROM pageviews_stream EMIT CHANGES;

# Cria uma tabela (objeto mutável) para um dos tópicos
CREATE TABLE users_table (id VARCHAR PRIMARY KEY) WITH (KAFKA_TOPIC='users', VALUE_FORMAT='AVRO');

# Select da tabela
SELECT * FROM USERS_TABLE EMIT CHANGES;

# Join do stream com a tabela
CREATE STREAM user_pageviews
  AS SELECT users_table.id AS userid, pageid, regionid, gender
    FROM pageviews_stream
    LEFT JOIN users_table ON pageviews_stream.userid = users_table.id
EMIT CHANGES;

# Select
SELECT * FROM user_pageviews EMIT CHANGES;

# Filtrando o stream
CREATE STREAM pageviews_region_like_89
  WITH (KAFKA_TOPIC='pageviews_filtered_r8_r9', VALUE_FORMAT='AVRO')
    AS SELECT * FROM user_pageviews
    WHERE regionid LIKE '%_8' OR regionid LIKE '%_9'
EMIT CHANGES;

# Select
SELECT * FROM pageviews_region_like_89 EMIT CHANGES;

# Window
CREATE TABLE pageviews_per_region_89 WITH (KEY_FORMAT='JSON')
  AS SELECT userid, gender, regionid, COUNT(*) AS numusers
    FROM pageviews_region_like_89
    WINDOW TUMBLING (SIZE 30 SECOND)
    GROUP BY userid, gender, regionid
    HAVING COUNT(*) > 1
EMIT CHANGES;

# Select
SELECT * FROM pageviews_per_region_89 EMIT CHANGES;



**********Projeto 6 - Multi-Broker Kafka Cluster com Docker: producer e consumer via Python**********
- Ferramentas:
Docker, kafka, python.

- Passos:
1-Criar container zookeeper, brocker;
2-Criar tópico e Streams para producer e consumer;
3-Acessar terminal externo do container broker e verificar a integração da camada de mensagens.

- Comandos:
#Parte 1
#Criando container zookeeper
1- Abra o prompt de comando ou terminal e execute o comando abaixo para criar o container do Zookeeper, o gerenciador do cluster Kafka.
docker run -d --name zookeeper2 --network dsa_dl_net -e ZOOKEEPER_CLIENT_PORT=2181 confluentinc/cp-zookeeper:latest

#Criando conrainers brockers
2- Abra o prompt de comando ou terminal e execute os comandos abaixo para criar os containers Kafka, os brokers do cluster.
docker run -d --name kafka-1 --network dsa_dl_net -p 9092:9092 -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka-1:9092 -e KAFKA_BROKER_ID=1 -e KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=2 -e KAFKA_ZOOKEEPER_CONNECT=zookeeper2:2181 confluentinc/cp-kafka:latest
docker run -d --name kafka-2 --network dsa_dl_net -p 9093:9092 -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka-2:9092 -e KAFKA_BROKER_ID=2 -e KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=2 -e KAFKA_ZOOKEEPER_CONNECT=zookeeper2:2181 confluentinc/cp-kafka:latest

#Criando Tópico no Kafka
1- Acesse o terminal de um dos containers Kafka e execute os comandos abaixo:
bash
cd /usr/bin
ls -la kafka*
./kafka-topics --create --bootstrap-server kafka-1:9092 --replication-factor 2 --partitions 1 --topic lab6
./kafka-topics --list --bootstrap-server kafka-1:9092
./kafka-topics --describe --bootstrap-server kafka-1:9092 --topic lab6

#Acessando o Tópico do Segundo Broker Kafka
1- Acesse o terminal do outro container Kafka e execute os comandos abaixo:
bash
cd /usr/bin
ls -la kafka*
./kafka-topics --list --bootstrap-server kafka-2:9092
./kafka-topics --describe --bootstrap-server kafka-2:9092 --topic lab6

#Produzindo Streams de Dados Para o Kafka
1- Acesse o terminal do container kafka-1 e execute os comandos abaixo:
bash
cd /usr/bin
./kafka-console-producer --bootstrap-server kafka-1:9092 --topic lab6

#Consumindo Streams de Dados do Kafka
1- Acesse o terminal do container kafka-2 e execute os comandos abaixo:
bash
cd /usr/bin
./kafka-console-consumer --bootstrap-server kafka-2:9092 --topic lab6 --from-beginning


- Passos:
1-Criar container cliente;
2-Criar arquivos para producer e consumer;
3-Acessar terminal externo do container cliente e verificar a integração da camada de mensagens.

#Parte 2
#Produzindo e Consumindo Stream de Dados do Cluster Kafka com Linguagem Python
1- Acesse o terminal da sua máquina e execute o comando abaixo:
docker run -dit --name cliente --network dsa_dl_net ubuntu

2- Execute o terminal do container e execute os comandos abaixo:
apt-get update

apt install wget curl vim nano default-jdk

cd ~

mkdir Lab6

wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh

bash Minicondpython

pip install confluent-kafka

# Crie os scripts producer.py e consumer.py na pasta Lab6
# Producer
from confluent_kafka import Producer

def delivery_report(err, msg):
    if err is not None:
        print('Entrega da mensagem falhou: {}'.format(err))
    else:
        print('Mensagem entregue com sucesso no tópico [{}]'.format(msg.topic()))

bootstrap_servers = '172.19.0.3:9092,172.19.0.4:9092'
topic = 'lab6'

conf = {'bootstrap.servers': bootstrap_servers}
producer = Producer(conf)

for i in range(10):
    message = f'registro_maquina {i}'
    producer.produce(topic, key=str(i), value=message, callback=delivery_report)
    producer.poll(0)

producer.flush()

# Consumer
from confluent_kafka import Consumer, KafkaError

bootstrap_servers = '172.19.0.3:9092,172.19.0.4:9092'
group_id = 'test_group'
topic = 'lab6'

conf = {
    'bootstrap.servers': bootstrap_servers,
    'group.id': group_id,
    'auto.offset.reset': 'earliest',
}

consumer = Consumer(conf)
consumer.subscribe([topic])

while True:
    msg = consumer.poll(1.0)

    if msg is None:
        continue
    if msg.error():
        print('Erro ao consumir a mensagem: {}'.format(msg.error()))
    else:
        print('Mensagem recebida: {}'.format(msg.value().decode('utf-8')))






**********Projeto 1 - Construindo Data Lake S3 com AWS Lake Formation e Análise Via SQL com Athena**********
- Ferramentas:
AWS S3, Lake Formation, Glue, Athena.

- Comandos:
- Acessar IAM e criar usuário e grupo;
-Adicionar o usuário ao grupo criado;
-Deslogar da AWS e acessar o endereço https://010928218238.signin.aws.amazon.com/console do usuário criado (Cria-se usuário para usar o Root);
-Preparar a fonte de dados (Bucket S3) com o arquivo bing_covid-19_data.parquet;
-Definir o adminstrador do Data Lake no console do Aws Lake Formation (Administrative roles and tasks / Data lake administrators = 	dsadlp1 / Database creators = IAMAllowedPrincipals)
-Apontar a fonte de dados (S3) para o Lake Formation (Data lake locations);
-Acessar Data locations para inferir qual usuário terá privilégio de acesso ao bucket s3
-Acessar Databases e criar o banco de dados com o arquivo do S3;
-Acessar o Crawlers e criar a tabela;
-Acessar Data Catalog > Tables no Aws Lake Formation > Actions > View Data (Vai abrir o Amazon Athena) para consultas SQL
-Criar no S3 um novo Bucket para a saída dos dados (p1-dsa-dl-saida > saida);
-Acessar novamente o Athena e configurar a saida de dados com a execução da Query da tabela.



**********Projeto 2 - Configurando o controle de acesso em nível de linha no DL através do Lake Formation**********




